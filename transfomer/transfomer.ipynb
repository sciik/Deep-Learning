{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fa28c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0f6495ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/ChatbotData .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a4cf6374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "cfacbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = [sentence for sentence in data[\"Q\"]]\n",
    "answer = [sentence for sentence in data[\"A\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "fc9938c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#구두점 분리\n",
    "#ㅋㅋㅋㅋㅋㅋㅋ, ㅎㅎㅎㅎㅎ, ㅠㅠㅠㅠㅠㅠ, ㅜㅜㅜ 두개로 통일\n",
    "#!!!, ~~~~, ;;;; 하나로 통일\n",
    "#큰따움표제거\n",
    "#영어 소문자 변경\n",
    "\n",
    "def preprocessing(sentences):\n",
    "    s = []\n",
    "    for sentence in sentences:\n",
    "        temp = sentence.lower().strip()\n",
    "        temp = re.sub(\"ㅋ+\", \" ㅋㅋ\", temp)\n",
    "        temp = re.sub(\"ㅎ+\", \" ㅎㅎ\", temp)\n",
    "        temp = re.sub(\"ㅜ+\", \" ㅜㅜ\", temp)\n",
    "        temp = re.sub(\"ㅠ+\", \" ㅠㅠ\", temp)\n",
    "        temp = re.sub(r\"!+\", \"!\", temp)\n",
    "        temp = re.sub(r\"~+\", \"~\", temp)\n",
    "        temp = re.sub(r\";+\", \";\", temp)\n",
    "        temp = re.sub(r\"\\\"\", \"\", temp)\n",
    "        temp = re.sub(r\"([.,!?~;])\", r\" \\1\", temp)\n",
    "        s.append(temp)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "afc9172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하~~~~~;;;;;;;;;;오늘ㅋㅋㅋㅋㅋㅋㅋㅋㅎㅎㅎㅎㅎㅠ!!!!!!!!!!!!~~~~~\n",
      "하 ~ ;오늘 ㅋㅋ ㅎㅎ ㅠㅠ ! ~\n"
     ]
    }
   ],
   "source": [
    "print(\"하~~~~~;;;;;;;;;;오늘ㅋㅋㅋㅋㅋㅋㅋㅋㅎㅎㅎㅎㅎㅠ!!!!!!!!!!!!~~~~~\")\n",
    "print(\" \".join(preprocessing([\"하~~~~~;;;;;;;;;;오늘ㅋㅋㅋㅋㅋㅋㅋㅋㅎㅎㅎㅎㅎㅠ!!!!!!!!!!!!~~~~~\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "47fad230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'ppl 심하네', 'sd카드 망가졌어', 'sd카드 안돼', 'sns 맞팔 왜 안하지 ㅠㅠ', 'sns 시간낭비인 거 아는데 매일 하는 중', 'sns 시간낭비인데 자꾸 보게됨']\n"
     ]
    }
   ],
   "source": [
    "question = preprocessing(question)\n",
    "answer = preprocessing(answer)\n",
    "\n",
    "print(question[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d41a6b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최소 길이 : 1\n",
      "질문의 최대 길이 : 57\n",
      "질문의 평균 길이 : 13.236319039160957\n",
      "응답의 최소 길이 : 1\n",
      "응답의 최대 길이 : 78\n",
      "응답의 평균 길이 : 16.03603146409541\n"
     ]
    }
   ],
   "source": [
    "question_len = [len(s) for s in question]\n",
    "answer_len = [len(s) for s in answer]\n",
    "\n",
    "plt.title('question')\n",
    "plt.hist(question_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('answer')\n",
    "plt.hist(answer_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "print('질문의 최소 길이 : {}'.format(np.min(question_len)))\n",
    "print('질문의 최대 길이 : {}'.format(np.max(question_len)))\n",
    "print('질문의 평균 길이 : {}'.format(np.mean(question_len)))\n",
    "print('응답의 최소 길이 : {}'.format(np.min(answer_len)))\n",
    "print('응답의 최대 길이 : {}'.format(np.max(answer_len)))\n",
    "print('응답의 평균 길이 : {}'.format(np.mean(answer_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9aede09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "min_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "19585262",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21824\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(question + answer, target_vocab_size=2<<14)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e526e185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [21824]\n",
      "END_TOKEN의 번호 : [21825]\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "55f81c7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder_input = []\n",
    "decoder_input = []\n",
    "decoder_output = []\n",
    "\n",
    "for (encoder_data, decoder_data) in zip(question, answer):\n",
    "    if (len(encoder_data) > min_len and len(encoder_data) <= max_len) and (len(decoder_data) > min_len and len(decoder_data) <= max_len):\n",
    "        encoder_input.append(START_TOKEN + tokenizer.encode(encoder_data) + END_TOKEN)\n",
    "        decoder_input.append(START_TOKEN + tokenizer.encode(decoder_data) + END_TOKEN)\n",
    "        decoder_output.append(tokenizer.encode(decoder_data) + END_TOKEN)\n",
    "        \n",
    "encoder_input = tf.keras.preprocessing.sequence.pad_sequences(encoder_input, maxlen=max_len, padding=\"post\")\n",
    "decoder_input = tf.keras.preprocessing.sequence.pad_sequences(decoder_input, maxlen=max_len-1, padding=\"post\")\n",
    "decoder_output = tf.keras.preprocessing.sequence.pad_sequences(decoder_output, maxlen=max_len-1, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fd37f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 11823\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((encoder_input, decoder_input), decoder_output))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "02ff1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "        \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "                                     i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "                                     d_model=d_model)\n",
    "\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a45f3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ae60cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "02d40bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9a190641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5fb19352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(units=units,\n",
    "                                d_model=d_model, \n",
    "                                num_heads=num_heads,\n",
    "                                dropout=dropout,\n",
    "                                name=\"encoder_layer_{}\".format(i),)([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c1d4edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={'query': inputs,\n",
    "                                                                                    'key': inputs,\n",
    "                                                                                    'value': inputs, \n",
    "                                                                                    'mask': look_ahead_mask})\n",
    "\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(inputs={'query': attention1,\n",
    "                                                                                    'key': enc_outputs,\n",
    "                                                                                    'value': enc_outputs,\n",
    "                                                                                    'mask': padding_mask})\n",
    "\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs=outputs,\n",
    "                          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "03c997ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(units=units,\n",
    "                                d_model=d_model,\n",
    "                                num_heads=num_heads,\n",
    "                                dropout=dropout,\n",
    "                                name='decoder_layer_{}'.format(i),)(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs=outputs,\n",
    "                          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "82d047af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(create_padding_mask, \n",
    "                                              output_shape=(1, 1, None), \n",
    "                                              name='enc_padding_mask')(inputs)\n",
    "\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(create_look_ahead_mask,\n",
    "                                             output_shape=(1, None, None),\n",
    "                                             name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(create_padding_mask, \n",
    "                                              output_shape=(1, 1, None),\n",
    "                                              name='dec_padding_mask')(inputs)\n",
    "\n",
    "    enc_outputs = encoder(vocab_size=vocab_size,\n",
    "                          num_layers=num_layers,\n",
    "                          units=units,\n",
    "                          d_model=d_model,\n",
    "                          num_heads=num_heads,\n",
    "                          dropout=dropout,)(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(vocab_size=vocab_size,\n",
    "                          num_layers=num_layers,\n",
    "                          units=units,\n",
    "                          d_model=d_model,\n",
    "                          num_heads=num_heads,\n",
    "                          dropout=dropout,)(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e6d58658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    7695872     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    8750592     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 21826)  5609282     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,055,746\n",
      "Trainable params: 22,055,746\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "NUM_LAYERS = 4\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "af60ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, max_len-1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "2e38f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "sample_learning_rate = CustomSchedule(d_model=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "fd36fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, max_len-1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "46ea1b48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 28s 384ms/step - loss: 1.4338 - accuracy: 0.0055\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 17s 377ms/step - loss: 1.3752 - accuracy: 0.0260\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 17s 370ms/step - loss: 1.3231 - accuracy: 0.0258\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 17s 369ms/step - loss: 1.2627 - accuracy: 0.0257\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 1.1847 - accuracy: 0.0396\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 1.0983 - accuracy: 0.0494\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 1.0179 - accuracy: 0.0498\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 17s 371ms/step - loss: 0.9453 - accuracy: 0.0500\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.8848 - accuracy: 0.0500\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.8353 - accuracy: 0.0500\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.7971 - accuracy: 0.0501\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.7675 - accuracy: 0.0508\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.7444 - accuracy: 0.0521\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.7257 - accuracy: 0.0527\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.7096 - accuracy: 0.0534\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.6952 - accuracy: 0.0541\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.6823 - accuracy: 0.0548\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.6689 - accuracy: 0.0555\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.6559 - accuracy: 0.0559\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.6427 - accuracy: 0.0565\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.6295 - accuracy: 0.0571\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.6149 - accuracy: 0.0580\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.6010 - accuracy: 0.0589\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 17s 375ms/step - loss: 0.5850 - accuracy: 0.0597\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.5674 - accuracy: 0.0612\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.5493 - accuracy: 0.0626\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.5306 - accuracy: 0.0643\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.5108 - accuracy: 0.0661\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.4904 - accuracy: 0.0683\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.4690 - accuracy: 0.0706\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.4460 - accuracy: 0.0732\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.4239 - accuracy: 0.0757\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 17s 375ms/step - loss: 0.4006 - accuracy: 0.0788\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.3773 - accuracy: 0.0820\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.3539 - accuracy: 0.0852\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.3302 - accuracy: 0.0888\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.3070 - accuracy: 0.0924\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.2846 - accuracy: 0.0952\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.2623 - accuracy: 0.0985\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.2405 - accuracy: 0.1020\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.2202 - accuracy: 0.1050\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1998 - accuracy: 0.1083\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1812 - accuracy: 0.1114\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1641 - accuracy: 0.1143\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1473 - accuracy: 0.1173\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1315 - accuracy: 0.1201\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1164 - accuracy: 0.1232\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.1038 - accuracy: 0.1256\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0918 - accuracy: 0.1278\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0804 - accuracy: 0.1301\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0710 - accuracy: 0.1319\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0620 - accuracy: 0.1337\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0542 - accuracy: 0.1352\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.0475 - accuracy: 0.1367\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0414 - accuracy: 0.1378\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0362 - accuracy: 0.1386\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0316 - accuracy: 0.1394\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.0280 - accuracy: 0.1400\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.0250 - accuracy: 0.1404\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0223 - accuracy: 0.1408\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0202 - accuracy: 0.1410\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0192 - accuracy: 0.1411\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.0179 - accuracy: 0.1412\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0161 - accuracy: 0.1414\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0148 - accuracy: 0.1417\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0141 - accuracy: 0.1418\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0133 - accuracy: 0.1418\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0130 - accuracy: 0.1418\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0120 - accuracy: 0.1420\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0126 - accuracy: 0.1418\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.0121 - accuracy: 0.1418\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0109 - accuracy: 0.1421\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0108 - accuracy: 0.1421\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0102 - accuracy: 0.1422\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0110 - accuracy: 0.1420\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0111 - accuracy: 0.1419\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0107 - accuracy: 0.1420\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0099 - accuracy: 0.1422\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0106 - accuracy: 0.1420\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0098 - accuracy: 0.1422\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0098 - accuracy: 0.1422\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0096 - accuracy: 0.1422\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.0098 - accuracy: 0.1422\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0093 - accuracy: 0.1423\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0097 - accuracy: 0.1422\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0098 - accuracy: 0.1421\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0100 - accuracy: 0.1420\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0091 - accuracy: 0.1423\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0088 - accuracy: 0.1423\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0088 - accuracy: 0.1423\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0079 - accuracy: 0.1426\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0076 - accuracy: 0.1427\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0079 - accuracy: 0.1426\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 17s 372ms/step - loss: 0.0072 - accuracy: 0.1428\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0074 - accuracy: 0.1427\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0071 - accuracy: 0.1428\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0068 - accuracy: 0.1430\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 17s 373ms/step - loss: 0.0066 - accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.0068 - accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 17s 374ms/step - loss: 0.0063 - accuracy: 0.1430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febc0203cd0>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1983ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocessing([sentence])\n",
    "    sentence = tokenizer.encode(sentence[0])\n",
    "    sentence = tf.expand_dims(START_TOKEN+sentence+END_TOKEN, axis=0)\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "24958ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d76e1fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 심심해요\n",
      "출력 : 저랑 놀아요 .\n",
      "저랑 놀아요 .\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(\"심심해요\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b6e31d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕하세요?\n",
      "출력 : 안녕하세요 .\n",
      "안녕하세요 .\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(\"안녕하세요?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f8b71245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 잘 지내?\n",
      "출력 : 당신은 잘 지내고 있나봅니다 .\n",
      "당신은 잘 지내고 있나봅니다 .\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(\"잘 지내?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "52e01abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 날씨 개좋음\n",
      "출력 : 모두를 위한 결심인지 확인해보세요 .\n",
      "모두를 위한 결심인지 확인해보세요 .\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(\"날씨 개좋음\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ec00900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 배고프다~~~~\n",
      "출력 : 저도 밥 먹고 싶어요\n",
      "저도 밥 먹고 싶어요\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(\"배고프다~~~~\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cccf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
